---
title: "Simulated examples"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Simulated examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.align="center",
  fig.width = 5,
  fig.height = 3
)
```

```{r, message=FALSE}
library(INLA)
library(ggplot2)
library(inlamemi)
library(dplyr)
```

This vignette shows how to fit measurement error and imputation models using the `inlamemi` package for a few different simple simulated data sets. Note that although the data sets describe realistic situations, they are all completely fictitious, and created purely to illustrate how to fit models in different situations.

## Simple example with missingness and two types of measurement error

|Error types | Likelihood | Response | Covariate with error | Other covariate(s) |
|:-----------|:----------|:--------|:----------|:------------|
|Berkson, classical, missing values | Gaussian | $y$ | $x$ | $z$ |

This is a simple simulation with Berkson and classical error as well as missing data, to check that the package works as expected in that scenario.

### Generating the data

```{r}
set.seed(2024)
n <- 1000

# Covariate without error:
z <- rnorm(n, mean = 0, sd = 1)

# Berkson error:
u_b <- rnorm(n, sd = 1)
alpha.0 <- 1; alpha.z <- 2
r <- rnorm(n, mean = alpha.0 + alpha.z*z, sd = 1)
x <- r + u_b # Turn off Berkson by commenting out "+ u_b"

# Response:
beta.0 <- 1; beta.x <- 2; beta.z <- 2
y <- beta.0 + beta.x*x + beta.z*z + rnorm(n)

# Classical error:
u_c <- rnorm(n, sd = 1)
x_obs <- r + u_c 

# Missingness:
m_pred <- -1.5 - 0.5*z # This gives a mean probability of missing of ca 0.2.
m_prob <- exp(m_pred)/(1 + exp(m_pred))

m_index <- as.logical(rbinom(n, 1, prob = m_prob)) # MAR
# m_index <- sample(1:n, 0.2*n, replace = FALSE) # MCAR
x_obs[m_index] <- NA

simple_data <- data.frame(y = y, x = x_obs, z = z)
```

### Fitting the model

```{r}
# Fit the model
simple_model <- fit_inlamemi(data = simple_data, 
                         formula_moi = y ~ x + z, 
                         formula_imp = x ~ z, 
                         family_moi = "gaussian",
                         error_type = c("berkson", "classical"),
                         prior.prec.moi = c(10, 9),       # Gamma(10, 9)
                         prior.prec.berkson = c(10, 9),   # Gamma(10, 9)
                         prior.prec.classical = c(10, 9), # Gamma(10, 9)
                         prior.prec.imp = c(10, 9),       # Gamma(10, 9)
                         prior.beta.error = c(0, 1/1000), # N(0, 10^3)
                         initial.prec.moi = 1,
                         initial.prec.berkson = 1,
                         initial.prec.classical = 1,
                         initial.prec.imp = 1)
summary(simple_model)
```


```{r}
simple.truth <- tibble::tribble(
  ~"variable", ~"value",
  "beta.x",  beta.x, 
  "beta.z",  beta.z, 
#  "beta.0",  beta.0, 
  "alpha.x.z", alpha.z, 
 # "alpha.0", alpha.0
  )

plot(simple_model, plot_intercepts = FALSE) +
    geom_point(data = simple.truth, aes(x = value))

```

## Missing data only 

|Error types | Likelihood | Response | Covariate with error | Other covariate(s) |
|:-----------|:----------|:--------|:----------|:------------|
|Missing values | Gaussian | $y$ | $x$ | $z$ |

In this example, we have missingness in one covariate, but no other measurement error, so this shows how to do simple imputation of a missing covariate in R-INLA.

### Generating the data

```{r}
set.seed(2024)
n <- 1000

# Covariate without missingness:
z <- rnorm(n, mean = 0, sd = 1)

# Covariate that will have missingness:
alpha.0 <- 1; alpha.z <- 2
x <- rnorm(n, mean = alpha.0 + alpha.z*z, sd = 1)

# Response:
beta.0 <- 1; beta.x <- 2; beta.z <- 2
y <- beta.0 + beta.x*x + beta.z*z + rnorm(n)

# Missingness:
m_pred <- -1.5 - 0.5*z # This gives a mean probability of missing of ca 0.2.
m_prob <- exp(m_pred)/(1 + exp(m_pred))

m_index <- as.logical(rbinom(n, 1, prob = m_prob)) # MAR
# m_index <- sample(1:n, 0.2*n, replace = FALSE) # MCAR
x_obs <- x
x_obs[m_index] <- NA

missing_data <- data.frame(y = y, x = x_obs, z = z)
```

### Model without imputation
```{r}
naive_model <- inla(formula = y ~ x + z, family = "gaussian", data = missing_data)

naive_model$summary.fixed
naive_model$summary.hyperpar
```
### Model with imputation
```{r}
missing_model <- fit_inlamemi(formula_moi = y ~ x + z,
                            formula_imp = x ~ z,
                            family_moi = "gaussian",
                            data = missing_data, 
                            error_type = "missing", 
                            prior.prec.moi = c(2, 1),
                            prior.prec.imp = c(2, 1),
                            prior.beta.error = c(0, 1/1000),
                            initial.prec.moi = 1,
                            initial.prec.imp = 1)

summary(missing_model)
```
```{r}
missing_truth <- tibble::tribble(
  ~"variable", ~"value",
  "beta.0", beta.0,
  "beta.x",  beta.x, 
  "beta.z",  beta.z,
  "alpha.x.0", alpha.0,
  "alpha.x.z", alpha.z
)

plot(missing_model) +
    geom_point(data = missing_truth, aes(x = value))
```


## Random effect in the main model

|Error types | Likelihood | Response | Covariate with error | Other covariate(s) |
|:-----------|:----------|:--------|:----------|:------------|
|Classical | Gaussian | $y$ | $x$ | $z$, random effect $w$ |

In this example, we simulate data that is grouped in such a way that it should be modelled with a random effect in the model of interest.

### Generating the data

```{r}
m <- 10 # number of groups
n <- 100 # number of observations per group
N <- m*n # total number of observations

sd_y <- 3 # sd for the noise
sd_w <- 2 # sd for random effect
sd_x <- 2 # sd for covariate without error
sd_u <- 1 # sd for measurement error

# Covariate without error
z <- rnorm(N, 0, 2)

# Covariate with error
x <- rnorm(N, 0, sd_x) # Independent of z, but can change that here
x_obs <- x + rnorm(N, 0, sd_u)

# Random effect
w_per_group <- rnorm(m, 0, sd_w)
w <- rep(w_per_group, each = n)

# Response
y <- 1 + 2*x + 2*z + w + rnorm(N, 0, sd_y)

reff_data <- data.frame(y = y, id = rep(1:m, each = n), x = x_obs, z = z)
```

### Fitting the model

Firstly, if we ignored the measurement error, we might fit a model like this:

```{r}
naive_model <- inla(y ~ x + z + f(id, model = "iid"),
                    data = reff_data,
                    family = "gaussian")
summary(naive_model)
```

```{r}
# curve(dgamma(x, shape = 1.5, rate = 2), to = 2)

reff_model <- fit_inlamemi(formula_moi = y ~ x + z + 
                         f(id, model = "iid", hyper = list(prec = list(initial = -15, param = c(2, 2)))),
                       formula_imp = x ~ 1,
                       family_moi = "gaussian",
                       error_type = "classical",
                       data = reff_data,
                       initial.prec.moi = 1/4, 
                       initial.prec.classical = 1, 
                       initial.prec.imp = 1/4,
                       prior.prec.moi = c(1, 4),
                       prior.prec.classical = c(10, 10),
                       prior.prec.imp = c(1, 4),
                       prior.beta.error = c(0, 1/1000))

summary(reff_model)

reff.truth <- tibble::tribble(
  ~"variable", ~"value",
  "beta.x",  2, 
  "beta.z",  2, 
  "beta.0",  1, 
  "alpha.x.0", 0
)

plot(reff_model) +
    geom_point(data = reff.truth, aes(x = value))
```


## Interaction effect with error variable

|Error types | Likelihood | Response | Covariate with error | Other covariate(s) |
|:-----------|:----------|:--------|:----------|:------------|
|Classical | Gaussian | $y$ | $x$ | categorical variable $s$, interaction effect $x:s$ |


Interaction effects between the error prone variable and an (assumed) error-free variable can also be used. The syntax is as normal, an interaction effect between variables `x` and `s` would be specified in the formula for the model of interest as `x:s`. 


### Generating the data

```{r}
set.seed(2024)
n <- 1000

# Covariate without error:
s <- c(rep(0, n/2), rep(1, n/2))

# Classical error:
x <- rnorm(n, mean = 0, sd = 2)
u_c <- rnorm(n, sd = 1)
x_obs <- x + u_c 

# Response:
beta.0 <- 1; beta.x.s <- 2
y <- beta.0 + beta.x*x + beta.x.s*x_obs*s + rnorm(n)

interact_data <- data.frame(y = y, x = x_obs, z = z, s = s)
```

### Fitting the model

```{r}
interact_model <- fit_inlamemi(formula_moi = y ~ x:s,
                             formula_imp = x ~ 1,
                             family_moi = "gaussian",
                             data = interact_data,
                             error_type = "classical",
                             prior.beta.error = c(0, 0.01),
                             prior.prec.moi = c(10, 9),
                             prior.prec.classical = c(10, 9),
                             prior.prec.imp = c(10, 8),
                             initial.prec.moi = 1,
                             initial.prec.classical = 1,
                             initial.prec.imp = 2)
```

```{r}
summary(interact_model)
plot(interact_model)
```




## Air pollution example 

|Error types | Likelihood | Response | Covariate with error | Other covariate(s) |
|:-----------|:----------|:--------|:----------|:------------|
|Berkson, classical | Binomial | asthma | airpollution | gender, age, district |

In this example, we simulate data from a fictitious, but realistic scenario where we want examine if people in areas with high air pollution seem to have asthma more than in areas with lower air pollution. But the air pollution value for the people in the study cannot be observed directly, instead sensors have been placed at certain locations, and the value for a person is set to be the value gathered at the closest sensor. This leads to a Berkson error. In addition to that, we believe that there is some noise in the measurements due to imprecision in the sensor. This corresponds to a classical measurement error. 

TODO: random intercept model for district instead of treating it as continuous variable.

### Generating the data

```{r}
set.seed(2034)
n <- 1000
gender <- sample(c(0,1), n, replace = TRUE)
age <- rgamma(n, shape = 10, scale = 3)
district <- sample(1:10, n, replace = TRUE)

alpha.0 <- 3; alpha.district <- 0.05
pollution_b <- alpha.0 + alpha.district*district + 
  rnorm(n, mean = 0, sd = 4) # Berkson error
pollution <- pollution_b + rnorm(n, 0, 1) # Classical and Berkson error (this is what is observed)
pollution_correct <- pollution_b + rnorm(n, mean = 0, sd = 2) # Correct

beta.0 <- -8; beta.pollution <- 1; beta.gender <- -1; 
beta.age <- 0.5; beta.district <- -2

asthma_predictor <- beta.0 + beta.pollution*pollution_correct + 
  beta.gender*gender + beta.age*age + beta.district*district
asthma_prob <- exp(asthma_predictor)/(1 + exp(asthma_predictor))
asthma <- rbinom(n, 1, prob = asthma_prob)

airpollution <- data.frame(asthma = asthma, 
                           pollution = pollution, 
                           district, 
                           age, 
                           gender)
```

### Fitting the model

```{r}
# Scale the data
airpollution_scaled <- airpollution %>% 
  mutate(across(c(pollution, age), ~ c(scale(., scale = FALSE))))

airpollution_moi <- asthma ~ pollution + district + age + gender
airpollution_imp <- pollution ~ district

airpollution_model <- fit_inlamemi(data = airpollution_scaled, 
                         formula_moi = airpollution_moi, 
                         formula_imp = airpollution_imp, 
                         family_moi = "binomial",
                         error_type = c("berkson", "classical"),
                         prior.prec.berkson = c(1000, 999), 
                         prior.prec.classical = c(1000, 999),
                         prior.prec.imp = c(0.5, 0.5),
                         prior.beta.error = c(0, 1/1000),
                         initial.prec.berkson = 1,
                         initial.prec.classical = 1,
                         initial.prec.imp = 1/16)

airpollution_summary <- summary(airpollution_model)

airpollution.truth <- tibble::tribble(
  ~"variable", ~"value",
  "beta.pollution", beta.pollution, 
  "beta.gender",    beta.gender, 
  "beta.district",  beta.district, 
  "beta.age",       beta.age, 
#  "beta.0",         beta.0, 
  "alpha.pollution.district", alpha.district, 
#  "alpha.0",        alpha.0
)

plot(airpollution_model, plot_intercepts = FALSE) +
  geom_point(data = airpollution.truth, aes(x = value))
```

## Poisson regression with classical error and missing data

|Error types | Likelihood | Response | Covariate with error | Other covariate(s) |
|:-----------|:----------|:--------|:----------|:------------|
| Classical, missing | Poisson | $y$ | $w$ | $z$ |

```{r}
set.seed(1)
nn <- 1000

z <- rbinom(nn, 1, 0.5)
x <- rnorm(nn, 1-0.5*z, 1)

# Error
w <- x + rnorm(nn, 0, 1)

# Generating missing data, depending on z
eta <- -1 + z
prob_missing <- exp(eta)/(1 + exp(eta))
missing_index <- rbinom(nn, 1, prob_missing)

# Proportion missing:
sum(missing_index)/nn

# Replace the values in w by missing in case the index for missingness is =1:
w <- ifelse(missing_index==1, NA, w)

# Random effect to include in the regression model:
re <- rep(rnorm(nn/20), each = 20)

# Linear predictor
eta <-  x + z + re  

# Generate Poisson response
y <- rpois(nn, exp(eta))

data_pois <- data.frame(x = x, z = z, y = y, w = w, id = rep(seq(1:50), each = 20))
```

Simple regression models with correct and error-prone variables to check the effect:

```{r, eval = FALSE}
library(lme4)
summary(glmer(y ~ x + z + (1|id), data = data_pois, family="poisson"))$coef

summary(glmer(y ~ w + z + (1|id), data = data_pois, family="poisson"))$coef
```


Modeling error and missing data with INLA:

```{r,eval=FALSE}
model_pois <- fit_inlamemi(data = data_pois,
                       formula_moi = y ~ w + z + f(id,model="iid"),
                       formula_imp = w ~ z,
                       formula_mis = m ~ z,
                       family_moi = "poisson",
                       error_type = c("classical","missing"),
                       prior.prec.classical = c(19, 9),
                       prior.prec.imp = c(10, 9),
                       prior.beta.error = c(0, 1/1000),
                       initial.prec.classical = 2,
                       initial.prec.imp = 1)

summary(model_pois)
plot(model_pois)
```


